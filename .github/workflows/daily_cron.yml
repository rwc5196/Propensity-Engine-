name: "Daily Pipeline Run"

on:
  schedule:
    - cron: '0 12 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.12'
  TZ: 'America/Chicago'

jobs:
  run-pipelines:
    name: "Execute Pipelines"
    runs-on: ubuntu-latest
    timeout-minutes: 45
    outputs:
      hot_leads_count: ${{ steps.scoring.outputs.hot_leads }}
      total_scored: ${{ steps.scoring.outputs.total_scored }}
      run_id: ${{ github.run_id }}
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: "Install dependencies"
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: "Configure environment"
        run: |
          cat > .env << 'ENVEOF'
          SUPABASE_URL=${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}
          GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
          GEMINI_FLASH_MODEL=gemini-2.0-flash-exp
          GEMINI_PRO_MODEL=gemini-1.5-pro
          FRED_API_KEY=${{ secrets.FRED_API_KEY }}
          BLS_API_KEY=${{ secrets.BLS_API_KEY }}
          SEC_USER_AGENT=PropensityEngine github-actions@${{ github.repository }}
          TARGET_CITIES=Dallas,Fort Worth,Arlington,Irving,Plano,Garland,Grand Prairie,McKinney,Frisco,Denton
          TARGET_STATE=TX
          TARGET_ZIPS=75001,75006,75019,75038,75039,75050,75060,75061,75062,76001,76010,76011,76012,76102,76103,76104
          WEIGHT_EXPANSION=0.25
          WEIGHT_DISTRESS=0.20
          WEIGHT_JOB_VELOCITY=0.20
          WEIGHT_SENTIMENT=0.15
          WEIGHT_MARKET_TIGHTNESS=0.10
          WEIGHT_MACRO=0.10
          HOT_LEAD_THRESHOLD=75
          MIN_PERMIT_VALUE=50000
          PERMIT_LOOKBACK_DAYS=30
          ENVEOF

      - name: "Pipeline 1: Building Permits"
        id: permits
        continue-on-error: true
        run: |
          echo "::group::Pipeline 1 Output"
          python -m pipelines.pipeline_1_permits 2>&1 || echo "Pipeline 1 completed with warnings"
          echo "::endgroup::"

      - name: "Pipeline 2: WARN Notices"
        id: warn
        continue-on-error: true
        run: |
          echo "::group::Pipeline 2 Output"
          python -m pipelines.pipeline_2_warn 2>&1 || echo "Pipeline 2 completed with warnings"
          echo "::endgroup::"

      - name: "Pipeline 3: Economic Indicators"
        id: macro
        continue-on-error: true
        run: |
          echo "::group::Pipeline 3 Output"
          python -m pipelines.pipeline_3_macro 2>&1 || echo "Pipeline 3 completed with warnings"
          echo "::endgroup::"

      - name: "Pipeline 4: Glassdoor Sentiment"
        id: glassdoor
        continue-on-error: true
        run: |
          echo "::group::Pipeline 4 Output"
          python -c "
          try:
              from pipelines import GlassdoorPipeline
              p = GlassdoorPipeline()
              p.run(['Amazon', 'XPO Logistics', 'FedEx', 'UPS', 'DHL'])
          except Exception as e:
              print(f'Pipeline 4 skipped: {e}')
          " 2>&1
          echo "::endgroup::"

      - name: "Pipeline 5: Job Postings"
        id: jobs
        continue-on-error: true
        run: |
          echo "::group::Pipeline 5 Output"
          python -m pipelines.pipeline_5_jobs 2>&1 || echo "Pipeline 5 completed with warnings"
          echo "::endgroup::"

      - name: "Pipeline 6: Inventory Turnover"
        id: inventory
        continue-on-error: true
        run: |
          echo "::group::Pipeline 6 Output"
          python -c "
          try:
              from pipelines import InventoryPipeline
              p = InventoryPipeline()
              p.run(['WMT', 'HD', 'TGT', 'COST', 'KR', 'LOW', 'BBY', 'DG', 'DLTR'])
          except Exception as e:
              print(f'Pipeline 6 skipped: {e}')
          " 2>&1
          echo "::endgroup::"

      - name: "Pipeline 7: Labor Market"
        id: labor
        continue-on-error: true
        run: |
          echo "::group::Pipeline 7 Output"
          python -m pipelines.pipeline_7_labor 2>&1 || echo "Pipeline 7 completed with warnings"
          echo "::endgroup::"

      - name: "Calculate Propensity Scores"
        id: scoring
        run: |
          python run_scoring.py
          if [ -f scoring_results.json ]; then
            HOT=$(python -c "import json; print(json.load(open('scoring_results.json'))['hot'])")
            TOTAL=$(python -c "import json; print(json.load(open('scoring_results.json'))['total'])")
            echo "hot_leads=$HOT" >> $GITHUB_OUTPUT
            echo "total_scored=$TOTAL" >> $GITHUB_OUTPUT
          else
            echo "hot_leads=0" >> $GITHUB_OUTPUT
            echo "total_scored=0" >> $GITHUB_OUTPUT
          fi

      - name: "Generate Run Report"
        run: |
          cat > run_report.json << REPORTEOF
          {
            "run_id": "${{ github.run_id }}",
            "run_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "trigger": "${{ github.event_name }}",
            "pipelines": {
              "permits": "${{ steps.permits.outcome }}",
              "warn": "${{ steps.warn.outcome }}",
              "macro": "${{ steps.macro.outcome }}",
              "glassdoor": "${{ steps.glassdoor.outcome }}",
              "jobs": "${{ steps.jobs.outcome }}",
              "inventory": "${{ steps.inventory.outcome }}",
              "labor": "${{ steps.labor.outcome }}"
            }
          }
          REPORTEOF
          cat run_report.json

      - name: "Upload artifacts"
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: |
            *.log
            *.json
          retention-days: 30

  export-sheets:
    name: "Export to Google Sheets"
    needs: run-pipelines
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: "Install dependencies"
        run: pip install gspread google-auth supabase python-dotenv

      - name: "Setup credentials"
        run: |
          echo '${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}' | base64 -d > credentials.json

      - name: "Export Enhanced Data to Sheets"
        env:
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SHEET_ID }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python << 'PYTHONEOF'
          import os
          import gspread
          from google.oauth2.service_account import Credentials
          from supabase import create_client
          from datetime import datetime

          print("Starting Google Sheets export...")

          # Connect to Supabase
          supabase = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])

          # Fetch all signal_history and company_master data
          print("Fetching data from Supabase...")
          sh_all = supabase.table('signal_history').select('*').execute()
          cm_all = supabase.table('company_master').select('*').execute()

          # Create lookup dict
          company_lookup = {c['id']: c for c in cm_all.data}

          # Merge and categorize leads
          all_leads = []
          for sh in sh_all.data:
              cid = sh.get('company_id')
              if cid and cid in company_lookup:
                  merged = {**sh, **company_lookup[cid]}
                  all_leads.append(merged)

          hot_leads = [l for l in all_leads if l.get('score_tier') == 'hot']
          warm_leads = [l for l in all_leads if l.get('score_tier') == 'warm']
          texas_leads = [l for l in hot_leads if l.get('state') == 'TX']

          print(f"Hot: {len(hot_leads)}, Warm: {len(warm_leads)}, Texas: {len(texas_leads)}")

          if not hot_leads:
              print("No hot leads to export")
              exit(0)

          # Connect to Google Sheets
          creds = Credentials.from_service_account_file('credentials.json', scopes=[
              'https://www.googleapis.com/auth/spreadsheets',
              'https://www.googleapis.com/auth/drive'
          ])
          gc = gspread.authorize(creds)
          sheet = gc.open_by_key(os.environ['GOOGLE_SHEET_ID'])

          # Helper function for revenue formatting
          def fmt_rev(r):
              if not r:
                  return ''
              try:
                  r = float(r)
                  if r >= 1e9:
                      return f"${r/1e9:.1f}B"
                  if r >= 1e6:
                      return f"${r/1e6:.1f}M"
                  if r >= 1e3:
                      return f"${r/1e3:.0f}K"
                  return ''
              except:
                  return ''

          # ========================================
          # SHEET 1: HOT LEADS (Full 42 columns)
          # ========================================
          print("Exporting Hot Leads...")
          try:
              ws_hot = sheet.worksheet('Hot Leads')
          except gspread.WorksheetNotFound:
              ws_hot = sheet.add_worksheet('Hot Leads', rows=2000, cols=45)

          hot_headers = [
              'Company Name', 'City', 'State', 'Zip', 'Industry',
              'Score', 'Tier', 'Dominant Signal', 'Priority Tier', 'Staffing Fit',
              'Expansion', 'Distress', 'Job Velocity', 'Sentiment', 'Market',
              'Actively Hiring', 'Competitive', 'Seasonal',
              'Est Employees', 'Revenue', 'Revenue Raw',
              'Contact Name', 'Contact Title', 'Contact Email', 'Contact Phone', 'LinkedIn',
              'Current Vendor', 'Uses Staffing', 'Temp HC', 'Union', 'Season Pattern',
              'Pain Point', 'Pain Point 2', 'Value Prop', 'Email Template',
              'Services', 'Status', 'Last Outreach', 'Count', 'Next Action',
              'Website', 'Updated'
          ]

          ws_hot.clear()
          ws_hot.append_row(hot_headers)

          hot_rows = []
          for l in hot_leads:
              hot_rows.append([
                  l.get('company_name', ''),
                  l.get('city', ''),
                  l.get('state', ''),
                  l.get('zip_code', ''),
                  l.get('industry', ''),
                  l.get('propensity_score', 0),
                  l.get('score_tier', ''),
                  l.get('dominant_signal', ''),
                  l.get('priority_tier', ''),
                  l.get('staffing_fit_score', ''),
                  l.get('expansion_score', 0),
                  l.get('distress_score', 0),
                  l.get('job_velocity_score', 0),
                  l.get('sentiment_score', 0),
                  l.get('market_tightness_score', 0),
                  l.get('actively_hiring_score', 0),
                  l.get('competitive_pressure_score', 0),
                  l.get('seasonal_timing_score', 0),
                  l.get('employee_count_estimate', ''),
                  fmt_rev(l.get('annual_revenue')),
                  l.get('annual_revenue', ''),
                  l.get('primary_contact_name', ''),
                  l.get('primary_contact_title', ''),
                  l.get('primary_contact_email', ''),
                  l.get('primary_contact_phone', ''),
                  l.get('primary_contact_linkedin', ''),
                  l.get('current_staffing_provider', ''),
                  'Yes' if l.get('uses_staffing_agencies') else '',
                  l.get('estimated_temp_headcount', ''),
                  l.get('union_status', ''),
                  l.get('seasonal_pattern', ''),
                  l.get('primary_pain_point', ''),
                  l.get('secondary_pain_point', ''),
                  l.get('suggested_value_prop', ''),
                  l.get('suggested_email_template', ''),
                  l.get('recommended_services', ''),
                  l.get('outreach_status', 'Not Started'),
                  l.get('last_outreach_date', ''),
                  l.get('outreach_count', 0),
                  l.get('next_action', ''),
                  l.get('website', ''),
                  datetime.now().strftime('%Y-%m-%d %H:%M')
              ])

          if hot_rows:
              ws_hot.append_rows(hot_rows)
          print(f"Exported {len(hot_rows)} hot leads")

          # ========================================
          # SHEET 2: WARM LEADS
          # ========================================
          print("Exporting Warm Leads...")
          try:
              ws_warm = sheet.worksheet('Warm Leads')
          except gspread.WorksheetNotFound:
              ws_warm = sheet.add_worksheet('Warm Leads', rows=2000, cols=20)

          warm_headers = [
              'Company Name', 'City', 'State', 'Industry',
              'Score', 'Dominant Signal', 'Priority Tier',
              'Est Employees', 'Revenue',
              'Pain Point', 'Email Template', 'Services',
              'Website', 'Updated'
          ]

          ws_warm.clear()
          ws_warm.append_row(warm_headers)

          warm_rows = []
          for l in warm_leads[:1000]:
              warm_rows.append([
                  l.get('company_name', ''),
                  l.get('city', ''),
                  l.get('state', ''),
                  l.get('industry', ''),
                  l.get('propensity_score', 0),
                  l.get('dominant_signal', ''),
                  l.get('priority_tier', ''),
                  l.get('employee_count_estimate', ''),
                  fmt_rev(l.get('annual_revenue')),
                  l.get('primary_pain_point', ''),
                  l.get('suggested_email_template', ''),
                  l.get('recommended_services', ''),
                  l.get('website', ''),
                  datetime.now().strftime('%Y-%m-%d %H:%M')
              ])

          if warm_rows:
              ws_warm.append_rows(warm_rows)
          print(f"Exported {len(warm_rows)} warm leads")

          # ========================================
          # SHEET 3: DFW REGION (Texas Only)
          # ========================================
          print("Exporting DFW Region...")
          try:
              ws_tx = sheet.worksheet('DFW Region')
          except gspread.WorksheetNotFound:
              ws_tx = sheet.add_worksheet('DFW Region', rows=500, cols=20)

          tx_headers = [
              'Company Name', 'City', 'Zip', 'Industry',
              'Score', 'Dominant Signal', 'Priority Tier',
              'Est Employees', 'Revenue',
              'Pain Point', 'Email Template',
              'Contact Name', 'Contact Email',
              'Website', 'Updated'
          ]

          ws_tx.clear()
          ws_tx.append_row(tx_headers)

          tx_rows = []
          for l in texas_leads:
              tx_rows.append([
                  l.get('company_name', ''),
                  l.get('city', ''),
                  l.get('zip_code', ''),
                  l.get('industry', ''),
                  l.get('propensity_score', 0),
                  l.get('dominant_signal', ''),
                  l.get('priority_tier', ''),
                  l.get('employee_count_estimate', ''),
                  fmt_rev(l.get('annual_revenue')),
                  l.get('primary_pain_point', ''),
                  l.get('suggested_email_template', ''),
                  l.get('primary_contact_name', ''),
                  l.get('primary_contact_email', ''),
                  l.get('website', ''),
                  datetime.now().strftime('%Y-%m-%d %H:%M')
              ])

          if tx_rows:
              ws_tx.append_rows(tx_rows)
          print(f"Exported {len(tx_rows)} Texas leads")

          # ========================================
          # SHEET 4: SUMMARY DASHBOARD
          # ========================================
          print("Updating Summary Dashboard...")
          try:
              ws_sum = sheet.worksheet('Summary')
          except gspread.WorksheetNotFound:
              ws_sum = sheet.add_worksheet('Summary', rows=100, cols=10)

          ws_sum.clear()

          # Header
          ws_sum.append_row(['PROPENSITY ENGINE DASHBOARD', '', datetime.now().strftime('%Y-%m-%d %H:%M')])
          ws_sum.append_row([''])
          ws_sum.append_row(['LEAD COUNTS', ''])
          ws_sum.append_row(['Hot Leads (75+)', len(hot_leads)])
          ws_sum.append_row(['Warm Leads (50-74)', len(warm_leads)])
          ws_sum.append_row(['Texas/DFW Hot Leads', len(texas_leads)])
          ws_sum.append_row(['Total Companies', len(all_leads)])
          ws_sum.append_row([''])

          # Industry breakdown
          ws_sum.append_row(['TOP INDUSTRIES (Hot)', ''])
          industry_counts = {}
          for l in hot_leads:
              ind = l.get('industry', 'Unknown') or 'Unknown'
              industry_counts[ind] = industry_counts.get(ind, 0) + 1
          for ind, cnt in sorted(industry_counts.items(), key=lambda x: -x[1])[:10]:
              ws_sum.append_row([ind, cnt])

          ws_sum.append_row([''])

          # State breakdown
          ws_sum.append_row(['TOP STATES (Hot)', ''])
          state_counts = {}
          for l in hot_leads:
              st = l.get('state', 'Unknown') or 'Unknown'
              state_counts[st] = state_counts.get(st, 0) + 1
          for st, cnt in sorted(state_counts.items(), key=lambda x: -x[1])[:15]:
              ws_sum.append_row([st, cnt])

          ws_sum.append_row([''])

          # Template breakdown
          ws_sum.append_row(['EMAIL TEMPLATES', ''])
          template_counts = {}
          for l in hot_leads:
              tpl = l.get('suggested_email_template', 'None') or 'None'
              template_counts[tpl] = template_counts.get(tpl, 0) + 1
          for tpl, cnt in sorted(template_counts.items(), key=lambda x: -x[1]):
              ws_sum.append_row([tpl, cnt])

          print("Summary dashboard updated")
          print("Google Sheets export complete!")
          PYTHONEOF

  send-alerts:
    name: "Send Email Alerts"
    needs: run-pipelines
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: "Install dependencies"
        run: pip install resend supabase python-dotenv

      - name: "Send hot leads alert"
        env:
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python << 'PYTHONEOF'
          import os

          resend_key = os.environ.get('RESEND_API_KEY')
          alert_email = os.environ.get('ALERT_EMAIL')

          if not resend_key or not alert_email:
              print("Email not configured - skipping alerts")
              exit(0)

          import resend
          from supabase import create_client
          from datetime import datetime

          resend.api_key = resend_key

          # Fetch hot leads with company data
          supabase = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])

          sh_resp = supabase.table('signal_history').select('*').eq('score_tier', 'hot').limit(25).execute()
          cm_resp = supabase.table('company_master').select('*').execute()
          company_lookup = {c['id']: c for c in cm_resp.data}

          leads = []
          for sh in sh_resp.data:
              cid = sh.get('company_id')
              if cid and cid in company_lookup:
                  leads.append({**sh, **company_lookup[cid]})

          if not leads:
              print("No hot leads - skipping email")
              exit(0)

          # Format revenue helper
          def fmt_rev(r):
              if not r:
                  return 'N/A'
              try:
                  r = float(r)
                  if r >= 1e9:
                      return f"${r/1e9:.1f}B"
                  if r >= 1e6:
                      return f"${r/1e6:.1f}M"
                  return 'N/A'
              except:
                  return 'N/A'

          # Build enhanced email HTML
          rows_html = ""
          for l in leads:
              rows_html += f"""
              <tr>
                <td style="padding:8px;border-bottom:1px solid #eee">{l.get('company_name', 'N/A')}</td>
                <td style="padding:8px;border-bottom:1px solid #eee">{l.get('city', '')}, {l.get('state', '')}</td>
                <td style="padding:8px;border-bottom:1px solid #eee;font-weight:bold;color:#e74c3c">{l.get('propensity_score', 0)}</td>
                <td style="padding:8px;border-bottom:1px solid #eee">{l.get('dominant_signal', 'N/A')}</td>
                <td style="padding:8px;border-bottom:1px solid #eee">{fmt_rev(l.get('annual_revenue'))}</td>
                <td style="padding:8px;border-bottom:1px solid #eee">{l.get('suggested_email_template', 'N/A')}</td>
              </tr>
              """

          html = f"""
          <html>
          <body style="font-family:Arial,sans-serif;max-width:900px;margin:0 auto">
            <h2 style="color:#2c3e50">Hot Leads Detected - {len(leads)}</h2>
            <p style="color:#7f8c8d">Propensity Engine Daily Report - {datetime.now().strftime('%B %d, %Y')}</p>

            <table style="width:100%;border-collapse:collapse;margin-top:20px">
              <thead>
                <tr style="background:#3498db;color:white">
                  <th style="padding:12px;text-align:left">Company</th>
                  <th style="padding:12px;text-align:left">Location</th>
                  <th style="padding:12px;text-align:left">Score</th>
                  <th style="padding:12px;text-align:left">Signal</th>
                  <th style="padding:12px;text-align:left">Revenue</th>
                  <th style="padding:12px;text-align:left">Template</th>
                </tr>
              </thead>
              <tbody>
                {rows_html}
              </tbody>
            </table>

            <p style="margin-top:30px;padding:15px;background:#f8f9fa;border-radius:5px">
              <strong>Next Steps:</strong><br>
              1. Review full details in Google Sheets<br>
              2. Use assigned Email Templates for outreach<br>
              3. Track responses in Outreach Tracker
            </p>

            <p style="color:#95a5a6;font-size:12px">
              Enhanced report includes: Pain points, value propositions, contact fields, and recommended services.
            </p>
          </body>
          </html>
          """

          # Send email
          try:
              response = resend.Emails.send({
                  "from": "Propensity Engine <onboarding@resend.dev>",
                  "to": [alert_email],
                  "subject": f"Hot Leads Alert - {len(leads)} leads found",
                  "html": html
              })
              print(f"Email sent: {response}")
          except Exception as e:
              print(f"Email error: {e}")
          PYTHONEOF

  summary:
    name: "Generate Summary"
    needs: [run-pipelines, export-sheets, send-alerts]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: "Write job summary"
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'SUMMARYEOF'
          # Propensity Engine Daily Run

          **Date:** $(date '+%Y-%m-%d %H:%M %Z')
          **Run ID:** ${{ github.run_id }}

          ## Results

          | Metric | Value |
          |--------|-------|
          | Total Scored | ${{ needs.run-pipelines.outputs.total_scored }} |
          | Hot Leads | ${{ needs.run-pipelines.outputs.hot_leads_count }} |

          ## Pipeline Status

          | Pipeline | Status |
          |----------|--------|
          | 1. Permits | Check logs |
          | 2. WARN | Check logs |
          | 3. Economic | Check logs |
          | 4. Glassdoor | Check logs |
          | 5. Jobs | Check logs |
          | 6. Inventory | Check logs |
          | 7. Labor | Check logs |

          ## Job Status

          | Job | Status |
          |-----|--------|
          | Pipelines | ${{ needs.run-pipelines.result }} |
          | Sheets Export | ${{ needs.export-sheets.result }} |
          | Email Alerts | ${{ needs.send-alerts.result }} |

          ## Google Sheets Output

          | Sheet | Contents |
          |-------|----------|
          | Hot Leads | Full 42 columns with contact, pain points, templates |
          | Warm Leads | Key fields for nurturing pipeline |
          | DFW Region | Texas-only hot leads |
          | Summary | Dashboard with counts by industry/state |
          SUMMARYEOF
