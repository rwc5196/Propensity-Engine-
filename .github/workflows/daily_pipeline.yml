name: "Daily Pipeline + Sheets Export"

on:
  schedule:
    - cron: '0 12 * * *'  # 6 AM Central daily
  workflow_dispatch:
    inputs:
      refresh_signals:
        description: 'Also refresh external signals (WARN, jobs)?'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

jobs:
  pipeline-and-export:
    name: "Score & Export to Google Sheets"
    runs-on: ubuntu-latest
    
    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: "Install dependencies"
        run: pip install requests supabase gspread google-auth

      - name: "Run Pipeline & Export"
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GOOGLE_SHEETS_CREDS: ${{ secrets.GOOGLE_SHEETS_CREDS }}
          GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SHEET_ID }}
          REFRESH_SIGNALS: ${{ inputs.refresh_signals }}
        run: |
          python << 'PYTHONEOF'
          import os
          import json
          import gspread
          from datetime import datetime, timedelta
          from google.oauth2.service_account import Credentials
          from supabase import create_client

          # ================================================================
          # CONFIGURATION
          # ================================================================
          
          SUPABASE_URL = os.environ['SUPABASE_URL']
          SUPABASE_KEY = os.environ['SUPABASE_KEY']
          GOOGLE_SHEET_ID = os.environ['GOOGLE_SHEET_ID']
          
          supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
          
          # Google Sheets setup
          creds_json = json.loads(os.environ['GOOGLE_SHEETS_CREDS'])
          creds = Credentials.from_service_account_info(creds_json, scopes=[
              'https://www.googleapis.com/auth/spreadsheets',
              'https://www.googleapis.com/auth/drive'
          ])
          gc = gspread.authorize(creds)
          spreadsheet = gc.open_by_key(GOOGLE_SHEET_ID)
          
          print("=" * 70)
          print("PROPENSITY ENGINE - GOOGLE SHEETS EXPORT")
          print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
          print("=" * 70)

          # ================================================================
          # HELPER FUNCTIONS
          # ================================================================
          
          def get_or_create_sheet(name, rows=1000, cols=30):
              """Get existing sheet or create new one."""
              try:
                  return spreadsheet.worksheet(name)
              except gspread.WorksheetNotFound:
                  return spreadsheet.add_worksheet(title=name, rows=rows, cols=cols)
          
          def clear_and_write(sheet, data, start='A1'):
              """Clear sheet and write new data."""
              sheet.clear()
              if data:
                  sheet.update(start, data, value_input_option='USER_ENTERED')
          
          def format_date(dt):
              """Format datetime for display."""
              if not dt:
                  return ''
              if isinstance(dt, str):
                  try:
                      dt = datetime.fromisoformat(dt.replace('Z', '+00:00'))
                  except:
                      return dt[:10] if len(dt) >= 10 else dt
              return dt.strftime('%Y-%m-%d')

          # ================================================================
          # SHEET 1: SUMMARY DASHBOARD
          # ================================================================
          
          print("\nðŸ“Š Building Summary Dashboard...")
          
          # Fetch summary statistics
          hot_leads = supabase.table('signal_history').select('id', count='exact').eq('score_tier', 'hot').execute()
          warm_leads = supabase.table('signal_history').select('id', count='exact').eq('score_tier', 'warm').execute()
          cool_leads = supabase.table('signal_history').select('id', count='exact').eq('score_tier', 'cool').execute()
          
          # Contact enrichment stats
          with_pattern = supabase.table('company_master').select('id', count='exact').not_.is_('hunter_email_pattern', 'null').execute()
          with_contact = supabase.table('company_master').select('id', count='exact').not_.is_('primary_contact_email', 'null').execute()
          
          # Fortune 500 stats
          f500_count = supabase.table('company_master').select('id', count='exact').eq('is_fortune_500', True).execute()
          
          # Get recent activity
          recent_enriched = supabase.table('company_master').select(
              'company_name, hunter_lookup_date'
          ).not_.is_('hunter_lookup_date', 'null').order('hunter_lookup_date', desc=True).limit(5).execute()
          
          # Build summary data
          summary_data = [
              ['ðŸŽ¯ PROPENSITY ENGINE DASHBOARD', '', '', f'Last Updated: {datetime.now().strftime("%Y-%m-%d %H:%M")}'],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ“ˆ PIPELINE OVERVIEW', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Metric', 'Count', 'Percentage', 'Action'],
              ['ðŸ”¥ Hot Leads (85-100)', hot_leads.count or 0, '', 'â†’ Priority outreach this week'],
              ['ðŸŸ¡ Warm Leads (70-84)', warm_leads.count or 0, '', 'â†’ Nurture sequence'],
              ['ðŸ”µ Cool Leads (50-69)', cool_leads.count or 0, '', 'â†’ Monitor for signals'],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ“§ CONTACT ENRICHMENT STATUS', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Metric', 'Count', 'Rate', 'Status'],
              ['Companies with Email Pattern', with_pattern.count or 0, f'{((with_pattern.count or 0) / max((hot_leads.count or 1), 1) * 100):.1f}%', ''],
              ['Companies with Contact Email', with_contact.count or 0, f'{((with_contact.count or 0) / max((hot_leads.count or 1), 1) * 100):.1f}%', ''],
              ['Fortune 500 Companies', f500_count.count or 0, '', 'â†’ Use facility-level targeting'],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸš¨ MARKET SIGNALS & ALERTS', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Signal Type', 'This Week', 'This Month', 'Trend'],
              ['WARN Layoff Notices (TX)', 'â€”', 'â€”', 'â¬†ï¸ Check TWC website'],
              ['Indeed Job Postings (Light Industrial)', 'â€”', 'â€”', 'ðŸ“Š Monitor weekly'],
              ['Building Permits (DFW)', 'â€”', 'â€”', 'ðŸ—ï¸ New construction = hiring'],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['âœ… RECENT ENRICHMENT ACTIVITY', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Company', 'Enriched Date', '', ''],
          ]
          
          for r in (recent_enriched.data or []):
              summary_data.append([r.get('company_name', ''), format_date(r.get('hunter_lookup_date')), '', ''])
          
          summary_data.extend([
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ“‹ THIS WEEK\'S PRIORITIES', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Priority', 'Task', 'Target', 'Status'],
              ['1', 'Enrich top 20 hot leads (Hunter)', '20 companies', 'â¬œ Pending'],
              ['2', 'LinkedIn research for Fortune 500', '10 contacts', 'â¬œ Pending'],
              ['3', 'Send outreach to ready contacts', '15 emails', 'â¬œ Pending'],
              ['4', 'Review WARN notices for opportunities', 'Check daily', 'â¬œ Pending'],
              ['5', 'Update job posting signals', 'Weekly refresh', 'â¬œ Pending'],
          ])
          
          summary_sheet = get_or_create_sheet('ðŸ“Š Summary')
          clear_and_write(summary_sheet, summary_data)
          print(f"   âœ… Summary: Dashboard updated")

          # ================================================================
          # SHEET 2: HOT LEADS (Priority Outreach)
          # ================================================================
          
          print("\nðŸ”¥ Exporting Hot Leads...")
          
          # Get hot leads with all enrichment data
          hot_query = supabase.table('signal_history').select(
              '''
              company_id,
              propensity_score,
              priority_rank,
              score_tier,
              company_master (
                  id,
                  company_name,
                  city,
                  state,
                  website,
                  employee_count,
                  annual_revenue,
                  industry,
                  is_fortune_500,
                  hunter_email_pattern,
                  hunter_lookup_date,
                  primary_contact_name,
                  primary_contact_title,
                  primary_contact_email,
                  primary_contact_phone,
                  primary_contact_linkedin,
                  suggested_email_template
              )
              '''
          ).eq('score_tier', 'hot').not_.is_('priority_rank', 'null').order('priority_rank').limit(500).execute()
          
          hot_headers = [
              'Rank', 'Company', 'Score', 'City', 'State', 'Industry',
              'Employees', 'Revenue', 'F500', 'Website',
              'Email Pattern', 'Contact Name', 'Contact Title', 'Contact Email',
              'Contact Phone', 'LinkedIn', 'Template', 'Enriched Date',
              'Outreach Status', 'Notes'
          ]
          
          hot_rows = [hot_headers]
          for h in (hot_query.data or []):
              cm = h.get('company_master') or {}
              
              # Determine contact quality
              title = (cm.get('primary_contact_title') or '').lower()
              if 'procurement' in title or 'purchasing' in title:
                  contact_quality = 'ðŸŽ¯ Procurement'
              elif 'plant' in title or 'facility' in title:
                  contact_quality = 'âœ… Plant Mgr'
              elif 'operations' in title:
                  contact_quality = 'âœ… Operations'
              elif cm.get('primary_contact_name'):
                  contact_quality = 'âš ï¸ Other'
              else:
                  contact_quality = 'âŒ None'
              
              hot_rows.append([
                  h.get('priority_rank', ''),
                  cm.get('company_name', ''),
                  h.get('propensity_score', ''),
                  cm.get('city', ''),
                  cm.get('state', ''),
                  cm.get('industry', ''),
                  cm.get('employee_count', ''),
                  cm.get('annual_revenue', ''),
                  'âœ…' if cm.get('is_fortune_500') else '',
                  cm.get('website', ''),
                  cm.get('hunter_email_pattern', ''),
                  cm.get('primary_contact_name', ''),
                  cm.get('primary_contact_title', ''),
                  cm.get('primary_contact_email', ''),
                  cm.get('primary_contact_phone', ''),
                  cm.get('primary_contact_linkedin', ''),
                  cm.get('suggested_email_template', ''),
                  format_date(cm.get('hunter_lookup_date')),
                  '',  # Outreach status (manual)
                  ''   # Notes (manual)
              ])
          
          hot_sheet = get_or_create_sheet('ðŸ”¥ Hot Leads')
          clear_and_write(hot_sheet, hot_rows)
          print(f"   âœ… Hot Leads: {len(hot_rows)-1} companies exported")

          # ================================================================
          # SHEET 3: FORTUNE 500 TARGETS
          # ================================================================
          
          print("\nðŸ¢ Exporting Fortune 500 Targets...")
          
          f500_query = supabase.table('signal_history').select(
              '''
              company_id,
              propensity_score,
              priority_rank,
              company_master!inner (
                  id,
                  company_name,
                  city,
                  state,
                  website,
                  is_fortune_500,
                  fortune_500_rank,
                  hunter_email_pattern,
                  primary_contact_name,
                  primary_contact_title,
                  primary_contact_email
              )
              '''
          ).eq('company_master.is_fortune_500', True).order('priority_rank').execute()
          
          f500_headers = [
              'Priority', 'Company', 'Score', 'F500 Rank', 'City', 'State',
              'Website', 'Has Pattern', 'Contact Name', 'Contact Title',
              'Contact Email', 'Research Status', 'LinkedIn Search URL', 'Notes'
          ]
          
          f500_rows = [f500_headers]
          for f in (f500_query.data or []):
              cm = f.get('company_master') or {}
              company_name = cm.get('company_name', '')
              
              # Generate LinkedIn X-Ray URL
              xray_url = f'https://www.google.com/search?q=site:linkedin.com/in+"plant+manager"+"{company_name.replace(" ", "+")}"+"Texas"'
              
              # Research status
              if cm.get('primary_contact_email'):
                  status = 'âœ… Ready'
              elif cm.get('hunter_email_pattern'):
                  status = 'ðŸ” Need Contact'
              else:
                  status = 'âŒ Need Pattern'
              
              f500_rows.append([
                  f.get('priority_rank', ''),
                  company_name,
                  f.get('propensity_score', ''),
                  cm.get('fortune_500_rank', ''),
                  cm.get('city', ''),
                  cm.get('state', ''),
                  cm.get('website', ''),
                  'âœ…' if cm.get('hunter_email_pattern') else 'âŒ',
                  cm.get('primary_contact_name', ''),
                  cm.get('primary_contact_title', ''),
                  cm.get('primary_contact_email', ''),
                  status,
                  xray_url,
                  ''
              ])
          
          f500_sheet = get_or_create_sheet('ðŸ¢ Fortune 500')
          clear_and_write(f500_sheet, f500_rows)
          print(f"   âœ… Fortune 500: {len(f500_rows)-1} companies exported")

          # ================================================================
          # SHEET 4: READY TO CONTACT
          # ================================================================
          
          print("\nðŸ“§ Exporting Ready-to-Contact List...")
          
          ready_query = supabase.table('company_master').select(
              '''
              id,
              company_name,
              city,
              state,
              website,
              hunter_email_pattern,
              primary_contact_name,
              primary_contact_title,
              primary_contact_email,
              primary_contact_phone,
              primary_contact_linkedin,
              suggested_email_template
              '''
          ).not_.is_('primary_contact_email', 'null').not_.is_('hunter_email_pattern', 'null').limit(200).execute()
          
          ready_headers = [
              'Company', 'City', 'State', 'Contact Name', 'Title', 
              'Email', 'Phone', 'LinkedIn', 'Email Pattern',
              'Template', 'Sent Date', 'Response', 'Follow-up Date'
          ]
          
          ready_rows = [ready_headers]
          for r in (ready_query.data or []):
              ready_rows.append([
                  r.get('company_name', ''),
                  r.get('city', ''),
                  r.get('state', ''),
                  r.get('primary_contact_name', ''),
                  r.get('primary_contact_title', ''),
                  r.get('primary_contact_email', ''),
                  r.get('primary_contact_phone', ''),
                  r.get('primary_contact_linkedin', ''),
                  r.get('hunter_email_pattern', ''),
                  r.get('suggested_email_template', ''),
                  '',  # Sent date (manual)
                  '',  # Response (manual)
                  ''   # Follow-up (manual)
              ])
          
          ready_sheet = get_or_create_sheet('ðŸ“§ Ready to Contact')
          clear_and_write(ready_sheet, ready_rows)
          print(f"   âœ… Ready to Contact: {len(ready_rows)-1} contacts exported")

          # ================================================================
          # SHEET 5: ENRICHMENT QUEUE
          # ================================================================
          
          print("\nðŸ” Exporting Enrichment Queue...")
          
          # Companies needing enrichment (have score but no pattern)
          queue_query = supabase.table('signal_history').select(
              '''
              company_id,
              propensity_score,
              priority_rank,
              company_master (
                  id,
                  company_name,
                  city,
                  state,
                  website,
                  hunter_email_pattern,
                  hunter_lookup_date,
                  primary_contact_name
              )
              '''
          ).eq('score_tier', 'hot').not_.is_('priority_rank', 'null').order('priority_rank').limit(300).execute()
          
          queue_headers = [
              'Rank', 'Company', 'Score', 'City', 'State', 'Website',
              'Has Pattern', 'Has Contact', 'Hunter Date', 'Action Needed'
          ]
          
          queue_rows = [queue_headers]
          for q in (queue_query.data or []):
              cm = q.get('company_master') or {}
              
              has_pattern = bool(cm.get('hunter_email_pattern'))
              has_contact = bool(cm.get('primary_contact_name'))
              
              if not cm.get('website'):
                  action = 'âš ï¸ No website'
              elif not has_pattern:
                  action = 'ðŸ”´ Run Hunter'
              elif not has_contact:
                  action = 'ðŸŸ¡ Run X-Ray/Apollo'
              else:
                  action = 'âœ… Complete'
              
              queue_rows.append([
                  q.get('priority_rank', ''),
                  cm.get('company_name', ''),
                  q.get('propensity_score', ''),
                  cm.get('city', ''),
                  cm.get('state', ''),
                  cm.get('website', ''),
                  'âœ…' if has_pattern else 'âŒ',
                  'âœ…' if has_contact else 'âŒ',
                  format_date(cm.get('hunter_lookup_date')),
                  action
              ])
          
          queue_sheet = get_or_create_sheet('ðŸ” Enrichment Queue')
          clear_and_write(queue_sheet, queue_rows)
          print(f"   âœ… Enrichment Queue: {len(queue_rows)-1} companies exported")

          # ================================================================
          # SHEET 6: MARKET SIGNALS (WARN, Jobs, Permits)
          # ================================================================
          
          print("\nðŸ“¡ Exporting Market Signals...")
          
          signals_data = [
              ['ðŸ“¡ MARKET SIGNALS TRACKER', '', '', f'Updated: {datetime.now().strftime("%Y-%m-%d")}'],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸš¨ WARN LAYOFF NOTICES (Texas)', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Instructions: Check TWC WARN list weekly at https://www.twc.texas.gov/businesses/worker-adjustment-and-retraining-notification-warn-notices'],
              ['Look for: Light industrial, manufacturing, warehouse, distribution companies in DFW'],
              ['Opportunity: Companies laying off often need temp workers to backfill or transition'],
              [''],
              ['Date', 'Company', 'Location', 'Affected Workers', 'Layoff Date', 'Opportunity Score', 'Notes'],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ’¼ INDEED JOB POSTING VELOCITY', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Track: Search Indeed for "[Company] warehouse Texas" weekly'],
              ['High posting velocity (5+ jobs/week) = urgent staffing need = hot lead'],
              [''],
              ['Week', 'Company', 'Job Count', 'Job Types', 'Locations', 'Velocity', 'Action'],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ—ï¸ BUILDING PERMITS (DFW)', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Track: New warehouse/industrial construction = future hiring'],
              ['Sources: City permit databases, Dallas Morning News, CoStar'],
              [''],
              ['Date', 'Company/Project', 'Location', 'Type', 'Size (sq ft)', 'Est. Completion', 'Opportunity'],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ“° NEWS & EXPANSION ALERTS', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Set up Google Alerts for: "[Company] expansion Texas", "[Company] hiring Texas"'],
              [''],
              ['Date', 'Company', 'Headline', 'Signal Type', 'Source', 'Action Taken', ''],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ðŸ“Š SIGNAL SUMMARY (This Month)', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Signal Type', 'Count', 'Converted to Leads', 'Conversion Rate', 'Top Opportunity', ''],
              ['WARN Notices', '', '', '', '', ''],
              ['Job Posting Spikes', '', '', '', '', ''],
              ['Building Permits', '', '', '', '', ''],
              ['News/Expansion', '', '', '', '', ''],
          ]
          
          signals_sheet = get_or_create_sheet('ðŸ“¡ Market Signals')
          clear_and_write(signals_sheet, signals_data)
          print(f"   âœ… Market Signals: Template created")

          # ================================================================
          # SHEET 7: CONTACT QUALITY BREAKDOWN
          # ================================================================
          
          print("\nðŸ‘¥ Exporting Contact Quality Analysis...")
          
          # Get all contacts with their quality
          contacts_query = supabase.table('company_master').select(
              'company_name, primary_contact_name, primary_contact_title, primary_contact_email, hunter_email_pattern'
          ).not_.is_('hunter_email_pattern', 'null').limit(500).execute()
          
          # Categorize contacts
          categories = {
              'ðŸŽ¯ Procurement': [],
              'âœ… Plant/Facility': [],
              'âœ… Operations': [],
              'ðŸŸ¡ HR': [],
              'âš ï¸ Other': [],
              'âŒ No Contact': []
          }
          
          for c in (contacts_query.data or []):
              title = (c.get('primary_contact_title') or '').lower()
              name = c.get('company_name', '')
              
              if not c.get('primary_contact_name'):
                  categories['âŒ No Contact'].append(name)
              elif 'procurement' in title or 'purchasing' in title:
                  categories['ðŸŽ¯ Procurement'].append(name)
              elif 'plant' in title or 'facility' in title:
                  categories['âœ… Plant/Facility'].append(name)
              elif 'operations' in title:
                  categories['âœ… Operations'].append(name)
              elif 'hr' in title or 'human resources' in title:
                  categories['ðŸŸ¡ HR'].append(name)
              else:
                  categories['âš ï¸ Other'].append(name)
          
          quality_data = [
              ['ðŸ‘¥ CONTACT QUALITY BREAKDOWN', '', f'Updated: {datetime.now().strftime("%Y-%m-%d")}'],
              [''],
              ['Category', 'Count', 'Percentage', 'Companies'],
          ]
          
          total = sum(len(v) for v in categories.values())
          for cat, companies in categories.items():
              pct = f'{len(companies)/max(total,1)*100:.1f}%'
              # Show first 5 companies
              company_list = ', '.join(companies[:5]) + ('...' if len(companies) > 5 else '')
              quality_data.append([cat, len(companies), pct, company_list])
          
          quality_data.extend([
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ACTION ITEMS', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              [f'1. Run LinkedIn X-Ray for {len(categories["âŒ No Contact"])} companies without contacts'],
              [f'2. Review {len(categories["âš ï¸ Other"])} companies with wrong contact type'],
              [f'3. {len(categories["ðŸŽ¯ Procurement"]) + len(categories["âœ… Plant/Facility"]) + len(categories["âœ… Operations"])} companies ready for outreach'],
          ])
          
          quality_sheet = get_or_create_sheet('ðŸ‘¥ Contact Quality')
          clear_and_write(quality_sheet, quality_data)
          print(f"   âœ… Contact Quality: Analysis complete")

          # ================================================================
          # SHEET 8: WEEKLY ACTIVITY LOG
          # ================================================================
          
          print("\nðŸ“… Creating Weekly Activity Log...")
          
          activity_data = [
              ['ðŸ“… WEEKLY ACTIVITY LOG', '', '', '', f'Week of: {datetime.now().strftime("%Y-%m-%d")}'],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['OUTREACH TRACKING', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Date', 'Company', 'Contact', 'Method', 'Template Used', 'Response', 'Next Step'],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              ['', '', '', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['ENRICHMENT ACTIVITY', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Date', 'Activity', 'Companies Processed', 'Results', 'Credits Used', 'Notes'],
              ['', 'Hunter.io Run', '', '', '', ''],
              ['', 'Apollo Run', '', '', '', ''],
              ['', 'LinkedIn X-Ray', '', '', '', ''],
              ['', 'Manual Research', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['WEEKLY METRICS', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['Metric', 'Target', 'Actual', 'Status', '', ''],
              ['Emails Sent', '15', '', '', '', ''],
              ['Responses Received', '3', '', '', '', ''],
              ['Meetings Booked', '1', '', '', '', ''],
              ['Companies Enriched', '20', '', '', '', ''],
              ['LinkedIn Searches', '10', '', '', '', ''],
              [''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              ['NOTES & LEARNINGS', '', '', '', '', ''],
              ['â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'],
              [''],
              ['', '', '', '', '', ''],
              ['', '', '', '', '', ''],
          ]
          
          activity_sheet = get_or_create_sheet('ðŸ“… Activity Log')
          clear_and_write(activity_sheet, activity_data)
          print(f"   âœ… Activity Log: Template created")

          # ================================================================
          # FINAL SUMMARY
          # ================================================================
          
          print("\n" + "=" * 70)
          print("EXPORT COMPLETE")
          print("=" * 70)
          print(f"""
          ðŸ“Š Summary Dashboard    - KPIs & priorities
          ðŸ”¥ Hot Leads           - {len(hot_rows)-1} priority companies
          ðŸ¢ Fortune 500         - {len(f500_rows)-1} enterprise targets
          ðŸ“§ Ready to Contact    - {len(ready_rows)-1} with email addresses
          ðŸ” Enrichment Queue    - {len(queue_rows)-1} needing research
          ðŸ“¡ Market Signals      - WARN, jobs, permits tracker
          ðŸ‘¥ Contact Quality     - Breakdown by contact type
          ðŸ“… Activity Log        - Weekly tracking template
          """)
          PYTHONEOF

      - name: "Write Summary"
        run: |
          echo "## Google Sheets Export Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Sheets Updated:" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š Summary Dashboard" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”¥ Hot Leads" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ¢ Fortune 500" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“§ Ready to Contact" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ” Enrichment Queue" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¡ Market Signals" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ‘¥ Contact Quality" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“… Activity Log" >> $GITHUB_STEP_SUMMARY
